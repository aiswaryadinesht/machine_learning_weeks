{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7d3201-fea5-4b6d-98f5-f1f740886247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'branch', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'uses', 'machine', 'learning', 'to', 'enable', 'computers', 'to', 'understand', 'and', 'communicate', 'with', 'human', 'language', '.']\n",
      "['NLP', 'is', 'used', 'in', 'many', 'products', ',', 'including', 'search', 'engines', ',', 'chatbots', ',', 'and', 'voice-operated', 'GPS', 'systems', '.']\n",
      "stemming\n",
      "['nlp', 'is', 'use', 'in', 'mani', 'product', ',', 'includ', 'search', 'engin', ',', 'chatbot', ',', 'and', 'voice-oper', 'gp', 'system', '.']\n",
      "---------lemmatize----\n",
      "['nlp', 'is', 'use', 'in', 'mani', 'product', ',', 'includ', 'search', 'engin', ',', 'chatbot', ',', 'and', 'voice-oper', 'gp', 'system', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "text=\"A branch of artificial intelligence (AI) that uses machine learning to enable computers to understand and communicate with human language. NLP is used in many products, including search engines, chatbots, and voice-operated GPS systems.\"\n",
    "sent_token=sent_tokenize(text)\n",
    "for sent in sent_token:\n",
    "    word_token=word_tokenize(sent)\n",
    "    print(word_token)\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "token=[stemmer.stem(word)for word in word_token]\n",
    "print(\"stemming\")\n",
    "print(token)\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "token=[lemmatizer.lemmatize(word)for word in token]\n",
    "print(\"---------lemmatize----\")\n",
    "print(token)\n",
    "\n",
    "# vect=TfidfVectorizer()\n",
    "# matrix=vect.fit_transform(word_token)\n",
    "# print(matrix.toarray())\n",
    "# vect2=CountVectorizer()\n",
    "# matrix2=vect2.fit_transform(word_token)\n",
    "# print(matrix2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f9f58-b791-40fb-93a5-ae7f89889973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
