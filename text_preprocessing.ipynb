{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0409a6b8-ee5d-4df5-99da-3dfe2165b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8755020080321285\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     comp.graphics       0.92      0.88      0.90       209\n",
      "  rec.sport.hockey       0.93      0.91      0.92       171\n",
      "         sci.space       0.80      0.88      0.84       202\n",
      "talk.politics.misc       0.86      0.83      0.85       165\n",
      "\n",
      "          accuracy                           0.88       747\n",
      "         macro avg       0.88      0.87      0.88       747\n",
      "      weighted avg       0.88      0.88      0.88       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load dataset\n",
    "categories = ['sci.space', 'rec.sport.hockey', 'comp.graphics', 'talk.politics.misc']\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'text': newsgroups.data, 'label': newsgroups.target})\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=newsgroups.target_names)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea04c20-9dfb-40a8-bd4c-7a4a898632fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...      7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...      1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "# categories = ['sci.space', 'rec.sport.hockey', 'comp.graphics', 'talk.politics.misc']\n",
    "newsgroups = fetch_20newsgroups()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'text': newsgroups.data, 'label': newsgroups.target})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033dc701-2ff6-459e-80a5-99ba7293aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d184e11e-2bc8-4ce9-b56e-cb11150a85fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        lerxstwamumdedu wheres thing subject car nntpp...\n",
       "1        guykuocarsonuwashingtonedu guy kuo subject si ...\n",
       "2        twillisececnpurdueedu thomas e willis subject ...\n",
       "3        jgreenamber joe green subject weitek p organiz...\n",
       "4        jcmheadcfaharvardedu jonathan mcdowell subject...\n",
       "                               ...                        \n",
       "11309    jimzisfeinfactorycom jim zisfein subject migra...\n",
       "11310    ebodinpearltuftsedu subject screen death mac p...\n",
       "11311    westesnetcomcom estes subject mounting cpu coo...\n",
       "11312    stevehcrlgw steven collins subject sphere poin...\n",
       "11313    gunningccocaltechedu kevin j gunning subject s...\n",
       "Name: cleaned_text, Length: 11314, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf05a97-a1a9-4986-bcca-df020f730f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8662b057-c32a-42ca-bb1a-620dc86dabb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8762704374723818\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.89      0.88      0.88        97\n",
      "           comp.graphics       0.76      0.88      0.82       104\n",
      " comp.os.ms-windows.misc       0.78      0.78      0.78       115\n",
      "comp.sys.ibm.pc.hardware       0.70      0.77      0.74       123\n",
      "   comp.sys.mac.hardware       0.89      0.79      0.84       126\n",
      "          comp.windows.x       0.83      0.85      0.84       106\n",
      "            misc.forsale       0.72      0.80      0.76       109\n",
      "               rec.autos       0.89      0.89      0.89       139\n",
      "         rec.motorcycles       0.93      0.91      0.92       122\n",
      "      rec.sport.baseball       0.94      0.98      0.96       102\n",
      "        rec.sport.hockey       0.98      0.94      0.96       108\n",
      "               sci.crypt       0.99      0.95      0.97       125\n",
      "         sci.electronics       0.83      0.81      0.82       114\n",
      "                 sci.med       0.93      0.96      0.94       119\n",
      "               sci.space       0.97      0.97      0.97       127\n",
      "  soc.religion.christian       0.86      0.88      0.87       122\n",
      "      talk.politics.guns       0.93      0.94      0.93       121\n",
      "   talk.politics.mideast       0.98      0.95      0.97       102\n",
      "      talk.politics.misc       0.90      0.90      0.90       107\n",
      "      talk.religion.misc       0.85      0.63      0.72        75\n",
      "\n",
      "                accuracy                           0.88      2263\n",
      "               macro avg       0.88      0.87      0.87      2263\n",
      "            weighted avg       0.88      0.88      0.88      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=newsgroups.target_names)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c092cb0-0336-44f8-8f1d-578c585fc0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
